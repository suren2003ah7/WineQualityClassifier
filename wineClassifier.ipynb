{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c906722f",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba42295",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d0df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = pd.read_csv(\"winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a4aba",
   "metadata": {},
   "source": [
    "# Describe Data\n",
    "\n",
    "The data consists of 11 features and one target (output) value. The input features based on physicochemical tests are as follows:\n",
    "\n",
    "1 - **fixed acidity** - The term refers to the amount of acids which do not evaporate easily during fermentation and aging and end up in the final bottled wine. It is a positive real number measured in grams per liter (g/L). Usually, red wines have fixed acidity values between 4 g/L to 7 g/L, however this range is not strictly fixed.\n",
    "\n",
    "2 - **volatile acidity** - This feature is the counterpart of fixed acidity, however in this case it measures the amount of volatile acids in wine which are easily evaporating during fermentation and aging. Measured in g/L, usual values are between 0.3 g/L to 0.7 g/L.\n",
    "\n",
    "3 - **citric acid** - The amount of citric acid in wine, measured in g/L. Usual values range from 0 g/L to 1 g/L.\n",
    "\n",
    "4 - **residual sugar** - The amount of sugar left in wine after the fermentation process. It is used to balance acidity and makes red wine categorized into dry, semi-sweet and sweet variants. Once again, it is measured in g/L.\n",
    "\n",
    "5 - **chlorides** - The amount of chloride salts in red wine (typically NaCl). Measured in g/L, typical values range from 0.012 g/L to 0.1 g/L.\n",
    "\n",
    "6 - **free sulfur dioxide** - Free sulfur dioxide (SO₂) in wine is the portion of sulfur dioxide that is not bound to other molecules and is active as an antimicrobial and antioxidant. It is measured in milligrams per liter (mg/L) and has typical values from 1 mg/L to 30 mg/L.\n",
    "\n",
    "7 - **total sulfur dioxide** - Total sulfur dioxide in wine includes both free and bound forms of SO₂. Once again, it is measured in mg/L. Typical values range from 10 mg/L to 150 mg/L.\n",
    "\n",
    "8 - **density** - The density feature shows how close the wine molecules are located to each other, it measures how heavier or lighter the wine is compared to water. Density for wines is measure in grams per cubic centimeter (g/cm³). Typical values range from 0.99 g/cm³ to 1.003 g/cm³.\n",
    "\n",
    "9 - **pH** - This feature measures the concentration of positive hydrogen ions in wine, which in simple terms shows the acidity of wine. pH values range from 1 to 13, where a pH value of 7 means the substance in completely neutral, lower values indicate acidic environment, and higher values indicate a basic one. The feature has no measure of units. Typical values fall into the range from 3.2 to 3.6.\n",
    "\n",
    "10 - **sulphates** - The amount of sulphates in wine measured in g/L. Typical value range is from 0.3 g/L to 1 g/L.\n",
    "\n",
    "11 - **alcohol** - Finally, the last feature shows the percentage of alcohol (ethanol content) present in wine. It is measured in percents and has typical values between 12% to 14.5%.\n",
    "\n",
    "The output value is the **wine quality score**, which is an **integer** from 0 to 10. Lower scores represent poor wine quality, while high scores represent excellent quality.\n",
    "\n",
    "Find more information about the dataset and it's origins [here](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b4833",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satine Aghababyan\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = wine_data\n",
    "\n",
    "print(\"\\nFirst few lines for display\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nSummary Statistics\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nMissing Values\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nDistribution of Features\")\n",
    "numeric_features = df.columns[:-1]\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(numeric_features, 1):\n",
    "    plt.subplot(3, 4, i)\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Էս մի հատ նայեք՝ պետք ա թե չէ\n",
    "print(\"\\nBoxplot Distribution of Features (for detecting outliers)\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(numeric_features, 1):\n",
    "    plt.subplot(3, 4, i)\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Էս փակագծերում գրածներս կարանք քոմենթ սարքենք եսլի չտո, կամ հանենք present անելուց կասենք\n",
    "print(\"\\nCount of Quality (for understanding if our data is balanced or biased)\")\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='quality', data=df)\n",
    "plt.title('Wine Quality Distribution')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelation\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature vs Quality\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(numeric_features, 1):\n",
    "    plt.subplot(3, 4, i)\n",
    "    sns.boxplot(x='quality', y=col, data=df)\n",
    "    plt.title(f'{col} vs Quality')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMissing Vales Count\")\n",
    "total_rows = len(df)\n",
    "missing_counts = df.isnull().sum()\n",
    "present_counts = total_rows - missing_counts\n",
    "columns = df.columns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "bars_present = ax.bar(columns, present_counts, color='skyblue', edgecolor='black', label='Present')\n",
    "\n",
    "bars_missing = ax.bar(columns, missing_counts, bottom=present_counts, color='salmon',\n",
    "                      edgecolor='black', hatch='///', label='Missing')\n",
    "\n",
    "ax.set_ylabel('Number of Values')\n",
    "ax.set_title('Present vs Missing Values per Feature')\n",
    "plt.xticks(rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nMean Feature Values per Wine Quality\")\n",
    "grouped_means = df.groupby('quality').mean()\n",
    "\n",
    "grouped_means_T = grouped_means.T\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "grouped_means_T.plot(kind='bar', figsize=(14, 8), colormap='viridis')\n",
    "\n",
    "plt.title('Mean Feature Values by Wine Quality')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.xlabel('Features')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Quality', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7705c113",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f849965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tigran Fahradyan\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "data = wine_data.to_numpy()\n",
    "\n",
    "CV = 5\n",
    "\n",
    "def split_data(data, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(len(data))\n",
    "    \n",
    "    train_end = int(0.9 * len(data))\n",
    "\n",
    "    train = data[indices[:train_end]]\n",
    "    test = data[indices[train_end:]]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def replace_nans(train, test):\n",
    "    train_mean = np.nanmean(train[:, :-1], axis=0)\n",
    "    for dataset in [train, test]:\n",
    "        for i in range(dataset.shape[1] - 1):\n",
    "            nan_mask = np.isnan(dataset[:, i])\n",
    "            dataset[nan_mask, i] = train_mean[i]\n",
    "    return train, test\n",
    "\n",
    "train, test = split_data(data, seed=42)\n",
    "train, test = replace_nans(train, test)\n",
    "\n",
    "X_train, y_train = train[:, :-1], train[:, -1].astype(int)\n",
    "X_test, y_test = test[:, :-1], test[:, -1].astype(int)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe12c8f",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469f8961",
   "metadata": {},
   "source": [
    "### Naive Bsyes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67897185",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, n_bins=10):\n",
    "        self.n_bins = n_bins\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_features = X.shape[1]\n",
    "        self.classes = np.unique(y)\n",
    "        self.K = len(self.classes)\n",
    "        self.N = len(y)\n",
    "\n",
    "        self.class_counts = {c: np.sum(y == c) for c in self.classes}\n",
    "        self.priors = {\n",
    "            c: (self.class_counts[c] + 1) / (self.N + self.K)\n",
    "            for c in self.classes\n",
    "        }\n",
    "\n",
    "        self.bins = []\n",
    "        self.X_binned = np.zeros_like(X, dtype=int)\n",
    "        for i in range(self.n_features):\n",
    "            col, edges = pd.cut(X[:, i], bins=self.n_bins, retbins=True, labels=False, duplicates='drop')\n",
    "            self.X_binned[:, i] = col\n",
    "            self.bins.append(edges)\n",
    "\n",
    "        self.feature_counts = {\n",
    "            c: np.zeros((self.n_features, self.n_bins), dtype=int)\n",
    "            for c in self.classes\n",
    "        }\n",
    "\n",
    "        for x, label in zip(self.X_binned, y):\n",
    "            for i, bin_idx in enumerate(x):\n",
    "                self.feature_counts[label][i][bin_idx] += 1\n",
    "\n",
    "    def _predict_sample(self, x):\n",
    "        x_binned = []\n",
    "        for i, val in enumerate(x):\n",
    "            bin_idx = np.digitize(val, self.bins[i]) - 1\n",
    "            bin_idx = min(max(bin_idx, 0), self.n_bins - 1)\n",
    "            x_binned.append(bin_idx)\n",
    "\n",
    "        best_class = None\n",
    "        max_log_prob = -np.inf\n",
    "\n",
    "        for c in self.classes:\n",
    "            log_prob = np.log(self.priors[c])\n",
    "\n",
    "            for i, bin_idx in enumerate(x_binned):\n",
    "                count = self.feature_counts[c][i][bin_idx]\n",
    "                total = self.class_counts[c]\n",
    "                prob = (count + 1) / (total + self.K)\n",
    "                log_prob += np.log(prob)\n",
    "\n",
    "            if log_prob > max_log_prob:\n",
    "                max_log_prob = log_prob\n",
    "                best_class = c\n",
    "\n",
    "        return best_class\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_sample(x) for x in X])\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)\n",
    "\n",
    "nb = NaiveBayes(n_bins=10)\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71715af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from itertools import product\n",
    "\n",
    "hparams = {\n",
    "    \"n_bins\": [5, 10, 20, 30]\n",
    "}\n",
    "\n",
    "param_combinations = list(product(*hparams.values()))\n",
    "param_names = list(hparams.keys())\n",
    "\n",
    "best_score = -1\n",
    "best_params = None\n",
    "best_model = None\n",
    "\n",
    "for combo in param_combinations:\n",
    "    params = dict(zip(param_names, combo))\n",
    "    scores = []\n",
    "    \n",
    "    kf = KFold(n_splits=CV, shuffle=True, random_state=42)\n",
    "    for train_index, val_index in kf.split(X_train):\n",
    "        X_tr, X_val = X_train[train_index], X_train[val_index]\n",
    "        y_tr, y_val = y_train[train_index], y_train[val_index]\n",
    "\n",
    "        nb = NaiveBayes(**params)\n",
    "        nb.fit(X_tr, y_tr)\n",
    "        score = nb.score(X_val, y_val)\n",
    "        scores.append(score)\n",
    "\n",
    "    avg_score = np.mean(scores)\n",
    "    \n",
    "    if avg_score > best_score:\n",
    "        best_score = avg_score\n",
    "        best_params = params\n",
    "        best_model = NaiveBayes(**params)\n",
    "        best_model.fit(X_train, y_train)\n",
    "\n",
    "test_preds = best_model.predict(X_test)\n",
    "test_acc = accuracy_score(y_test, test_preds)\n",
    "\n",
    "print(f\"The best hparam configuration for Naive Bayes is {best_params} with score {best_score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ca83c6",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "hparams_gnb = {\n",
    "    \"var_smoothing\": [1e-9, 1e-8, 1e-7, 1e-6, 1e-5]\n",
    "}\n",
    "\n",
    "gnb = GaussianNB()\n",
    "\n",
    "grid_search_gnb = GridSearchCV(\n",
    "    gnb,\n",
    "    param_grid=hparams_gnb,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=CV\n",
    ")\n",
    "grid_search_gnb.fit(X_train, y_train)\n",
    "\n",
    "best_gnb = grid_search_gnb.best_estimator_\n",
    "\n",
    "gnb_test_preds = best_gnb.predict(X_test)\n",
    "\n",
    "print(f\"The best hparam configuration for GaussianNB is {grid_search_gnb.best_params_} with score {grid_search_gnb.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd20abe8-9c9d-44b0-b8aa-034edd447025",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa66bf-2a45-44a1-92b0-3bbbbd09c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "hparams = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"splitter\": [\"best\", \"random\"],\n",
    "}\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "grid_search_decision_tree = GridSearchCV(\n",
    "    decision_tree,\n",
    "    param_grid=hparams,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=CV\n",
    ")\n",
    "grid_search_decision_tree.fit(X_train, y_train);\n",
    "\n",
    "dt = grid_search_decision_tree.best_estimator_\n",
    "\n",
    "print(f\"The best hparam configuration for decision tree is {grid_search_decision_tree.best_params_} with score {grid_search_decision_tree.best_score_:.4f}\")\n",
    "\n",
    "decision_tree_test_preds = grid_search_decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dc72cea",
   "metadata": {},
   "source": [
    "### k-nearest neighbour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb5cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_hparams = {\n",
    "    \"n_neighbors\": [3, 5, 7, 9, 11],\n",
    "    \"weights\": [\"uniform\", \"distance\"]\n",
    "}\n",
    "\n",
    "knn = KNeighborsClassifier()\n",
    "grid_search_knn = GridSearchCV(\n",
    "    knn,\n",
    "    param_grid=knn_hparams,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=CV\n",
    ")\n",
    "\n",
    "grid_search_knn.fit(X_train_scaled, y_train)\n",
    "\n",
    "knn_best = grid_search_knn.best_estimator_\n",
    "\n",
    "print(f\"The best hparam configuration for knn is {grid_search_knn.best_params_} with score {grid_search_knn.best_score_:.4f}\")\n",
    "\n",
    "knn_test_preds = knn_best.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3034021",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0a1a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "hparams_rf = {\n",
    "    \"n_estimators\": [50, 100],\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"max_depth\": [None, 10, 20],\n",
    "    \"min_samples_split\": [2, 5],\n",
    "    \"min_samples_leaf\": [1, 2],\n",
    "    \"bootstrap\": [True, False]\n",
    "}\n",
    "\n",
    "random_forest = RandomForestClassifier(random_state=42)\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    random_forest,\n",
    "    param_grid=hparams_rf,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=CV,\n",
    "    n_jobs=-1\n",
    ")\n",
    "grid_search_rf.fit(X_train, y_train)\n",
    "\n",
    "best_rf = grid_search_rf.best_estimator_\n",
    "\n",
    "rf_test_preds = best_rf.predict(X_test)\n",
    "\n",
    "print(f\"The best hparam configuration for Random Forest is {grid_search_rf.best_params_} with score {grid_search_rf.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f02ade1",
   "metadata": {},
   "source": [
    "### Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "053b6a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "hparam_grid = [\n",
    "    {\"solver\": [\"svd\"], \"shrinkage\": [None]},\n",
    "    {\"solver\": [\"lsqr\"], \"shrinkage\": [None, \"auto\", 0.1, 0.5, 0.9]},\n",
    "    {\"solver\": [\"eigen\"], \"shrinkage\": [None, \"auto\", 0.1, 0.5, 0.9]},\n",
    "]\n",
    "\n",
    "\n",
    "param_grid = list(ParameterGrid(hparam_grid))\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "\n",
    "grid_search_lda = GridSearchCV(\n",
    "    LinearDiscriminantAnalysis(),\n",
    "    param_grid=hparam_grid,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=CV,\n",
    "    n_jobs=-1,\n",
    "    error_score='raise'\n",
    ")\n",
    "\n",
    "\n",
    "grid_search_lda.fit(X_train, y_train)\n",
    "\n",
    "best_lda = grid_search_lda.best_estimator_\n",
    "lda_test_preds = best_lda.predict(X_test)\n",
    "\n",
    "print(f\"The best hparam configuration for LDA is {grid_search_lda.best_params_} with score {grid_search_lda.best_score_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a215ce3",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8132fefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "logreg_hparams = {\n",
    "    \"penalty\": [None, \"l2\"],\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"solver\": [\"lbfgs\", \"newton-cg\", \"newton-cholesky\", \"sag\"]\n",
    "}\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "grid_search_logreg = GridSearchCV(\n",
    "    logreg,\n",
    "    param_grid=logreg_hparams,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=CV\n",
    ")\n",
    "\n",
    "grid_search_logreg.fit(X_train_scaled, y_train)\n",
    "\n",
    "logreg_best = grid_search_logreg.best_estimator_\n",
    "\n",
    "print(f\"The best hparam configuration for logistic regression is {grid_search_logreg.best_params_} with score {grid_search_logreg.best_score_:.4f}\")\n",
    "\n",
    "logreg_test_preds = logreg_best.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b741f6",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668f8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_hparams = {\n",
    "    \"C\": [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    \"kernel\": [\"linear\", \"poly\", \"rbf\"]\n",
    "}\n",
    "\n",
    "svc = SVC()\n",
    "grid_search_svc = GridSearchCV(\n",
    "    svc,\n",
    "    param_grid=svc_hparams,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=CV\n",
    ")\n",
    "grid_search_svc.fit(X_train_scaled, y_train)\n",
    "\n",
    "svc_best = grid_search_svc.best_estimator_\n",
    "\n",
    "print(f\"The best hparam configuration for support vector machine is {grid_search_svc.best_params_} with score {grid_search_svc.best_score_:.4f}\")\n",
    "\n",
    "svc_test_preds = svc_best.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e8c14a",
   "metadata": {},
   "source": [
    "### Quadratic Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69bf49b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda_hparams = {\n",
    "    'reg_param': [0.0, 0.01, 0.1, 0.5, 0.9],\n",
    "    'tol': [1e-4, 1e-3, 1e-2, 1e-1]\n",
    "}\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "grid_search_qda = GridSearchCV(\n",
    "    qda,\n",
    "    param_grid=qda_hparams,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=CV\n",
    ")\n",
    "grid_search_qda.fit(X_train, y_train)\n",
    "\n",
    "qda_best = grid_search_qda.best_estimator_\n",
    "\n",
    "print(f\"The best hparam configuration for quadratic discriminant analysis is {grid_search_qda.best_params_} with score {grid_search_qda.best_score_:.4f}\")\n",
    "\n",
    "qda_test_preds = qda_best.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ee7229",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5314d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import (\n",
    "    accuracy_score, precision_score, recall_score, f1_score,\n",
    "    confusion_matrix, classification_report\n",
    ")\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "\n",
    "def evaluate_model(name, y_true, y_pred, num_classes):\n",
    "    print(f\"=== {name} ===\")\n",
    "    print(f\"Accuracy: {accuracy_score(y_true, y_pred):.4f}\")\n",
    "    print(f\"Precision (macro): {precision_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "    print(f\"Recall (macro): {recall_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "    print(f\"F1 Score (macro): {f1_score(y_true, y_pred, average='macro'):.4f}\")\n",
    "    \n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_true, y_pred))\n",
    "    \n",
    "    all_classes = list(range(0, 11))\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=all_classes)\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\", xticklabels=range(num_classes), yticklabels=range(num_classes))\n",
    "    plt.title(f\"Confusion Matrix - {name}\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "#ROC curve\n",
    "    if num_classes == 2:\n",
    "        fpr, tpr, thresholds = roc_curve(y_true, y_pred)\n",
    "        roc_auc = auc(fpr, tpr)\n",
    "        \n",
    "        plt.figure(figsize=(6, 5))\n",
    "        plt.plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (area = {roc_auc:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(f\"ROC Curve - {name}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "        \n",
    "    elif num_classes > 2:\n",
    "        y_true_bin = label_binarize(y_true, classes=range(num_classes))\n",
    "        fpr, tpr, roc_auc = {}, {}, {}\n",
    "        for i in range(num_classes):\n",
    "            fpr[i], tpr[i], _ = roc_curve(y_true_bin[:, i], y_pred == i)\n",
    "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "        plt.figure(figsize=(6, 5))\n",
    "        for i in range(num_classes):\n",
    "            plt.plot(fpr[i], tpr[i], lw=2, label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n",
    "        plt.plot([0, 1], [0, 1], color='gray', lw=2, linestyle='--')\n",
    "        plt.xlabel(\"False Positive Rate\")\n",
    "        plt.ylabel(\"True Positive Rate\")\n",
    "        plt.title(f\"ROC Curve (One-vs-Rest) - {name}\")\n",
    "        plt.legend(loc=\"lower right\")\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"\\n\")\n",
    "\n",
    "num_classes = len(np.unique(y_test))\n",
    "evaluate_model(\"Naive Bayes\", y_test, test_preds, num_classes)\n",
    "evaluate_model(\"Gaussian Naive Bayes\", y_test, gnb_test_preds, num_classes)\n",
    "evaluate_model(\"Decision Tree\", y_test, decision_tree_test_preds, num_classes)\n",
    "evaluate_model(\"Random Forest\", y_test, rf_test_preds, num_classes)\n",
    "evaluate_model(\"Linear Discriminant Analysis\", y_test, lda_test_preds, num_classes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c906722f",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509c118d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ba42295",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d0df4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_data = pd.read_csv(\"winequality-red.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "785a4aba",
   "metadata": {},
   "source": [
    "# Describe Data\n",
    "\n",
    "The data consists of 11 features and one target (output) value. The input features based on physicochemical tests are as follows:\n",
    "\n",
    "1 - **fixed acidity** - The term refers to the amount of acids which do not evaporate easily during fermentation and aging and end up in the final bottled wine. It is a positive real number measured in grams per liter (g/L). Usually, red wines have fixed acidity values between 4 g/L to 7 g/L, however this range is not strictly fixed.\n",
    "\n",
    "2 - **volatile acidity** - This feature is the counterpart of fixed acidity, however in this case it measures the amount of volatile acids in wine which are easily evaporating during fermentation and aging. Measured in g/L, usual values are between 0.3 g/L to 0.7 g/L.\n",
    "\n",
    "3 - **citric acid** - The amount of citric acid in wine, measured in g/L. Usual values range from 0 g/L to 1 g/L.\n",
    "\n",
    "4 - **residual sugar** - The amount of sugar left in wine after the fermentation process. It is used to balance acidity and makes red wine categorized into dry, semi-sweet and sweet variants. Once again, it is measured in g/L.\n",
    "\n",
    "5 - **chlorides** - The amount of chloride salts in red wine (typically NaCl). Measured in g/L, typical values range from 0.012 g/L to 0.1 g/L.\n",
    "\n",
    "6 - **free sulfur dioxide** - Free sulfur dioxide (SO₂) in wine is the portion of sulfur dioxide that is not bound to other molecules and is active as an antimicrobial and antioxidant. It is measured in milligrams per liter (mg/L) and has typical values from 1 mg/L to 30 mg/L.\n",
    "\n",
    "7 - **total sulfur dioxide** - Total sulfur dioxide in wine includes both free and bound forms of SO₂. Once again, it is measured in mg/L. Typical values range from 10 mg/L to 150 mg/L.\n",
    "\n",
    "8 - **density** - The density feature shows how close the wine molecules are located to each other, it measures how heavier or lighter the wine is compared to water. Density for wines is measure in grams per cubic centimeter (g/cm³). Typical values range from 0.99 g/cm³ to 1.003 g/cm³.\n",
    "\n",
    "9 - **pH** - This feature measures the concentration of positive hydrogen ions in wine, which in simple terms shows the acidity of wine. pH values range from 1 to 13, where a pH value of 7 means the substance in completely neutral, lower values indicate acidic environment, and higher values indicate a basic one. The feature has no measure of units. Typical values fall into the range from 3.2 to 3.6.\n",
    "\n",
    "10 - **sulphates** - The amount of sulphates in wine measured in g/L. Typical value range is from 0.3 g/L to 1 g/L.\n",
    "\n",
    "11 - **alcohol** - Finally, the last feature shows the percentage of alcohol (ethanol content) present in wine. It is measured in percents and has typical values between 12% to 14.5%.\n",
    "\n",
    "The output value is the **wine quality score**, which is an **integer** from 0 to 10. Lower scores represent poor wine quality, while high scores represent excellent quality.\n",
    "\n",
    "Find more information about the dataset and it's origins [here](https://www.kaggle.com/datasets/uciml/red-wine-quality-cortez-et-al-2009)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744b4833",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b848aa0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Satine Aghababyan\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "df = wine_data\n",
    "\n",
    "print(\"\\nFirst few lines for display\")\n",
    "print(df.head())\n",
    "\n",
    "print(\"\\nSummary Statistics\")\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\nMissing Values\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "print(\"\\nDistribution of Features\")\n",
    "numeric_features = df.columns[:-1]\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(numeric_features, 1):\n",
    "    plt.subplot(3, 4, i)\n",
    "    sns.histplot(df[col], kde=True)\n",
    "    plt.title(f'Distribution of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Էս մի հատ նայեք՝ պետք ա թե չէ\n",
    "print(\"\\nBoxplot Distribution of Features (for detecting outliers)\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(numeric_features, 1):\n",
    "    plt.subplot(3, 4, i)\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f'Boxplot of {col}')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "#Էս փակագծերում գրածներս կարանք քոմենթ սարքենք եսլի չտո, կամ հանենք present անելուց կասենք\n",
    "print(\"\\nCount of Quality (for understanding if our data is balanced or biased)\")\n",
    "plt.figure(figsize=(6, 4))\n",
    "sns.countplot(x='quality', data=df)\n",
    "plt.title('Wine Quality Distribution')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nCorrelation\")\n",
    "plt.figure(figsize=(12, 10))\n",
    "corr_matrix = df.corr()\n",
    "sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt='.2f')\n",
    "plt.title('Correlation Matrix')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature vs Quality\")\n",
    "plt.figure(figsize=(15, 10))\n",
    "for i, col in enumerate(numeric_features, 1):\n",
    "    plt.subplot(3, 4, i)\n",
    "    sns.boxplot(x='quality', y=col, data=df)\n",
    "    plt.title(f'{col} vs Quality')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nMissing Vales Count\")\n",
    "total_rows = len(df)\n",
    "missing_counts = df.isnull().sum()\n",
    "present_counts = total_rows - missing_counts\n",
    "columns = df.columns\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "bars_present = ax.bar(columns, present_counts, color='skyblue', edgecolor='black', label='Present')\n",
    "\n",
    "bars_missing = ax.bar(columns, missing_counts, bottom=present_counts, color='salmon',\n",
    "                      edgecolor='black', hatch='///', label='Missing')\n",
    "\n",
    "ax.set_ylabel('Number of Values')\n",
    "ax.set_title('Present vs Missing Values per Feature')\n",
    "plt.xticks(rotation=45)\n",
    "ax.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "print(\"\\nMean Feature Values per Wine Quality\")\n",
    "grouped_means = df.groupby('quality').mean()\n",
    "\n",
    "grouped_means_T = grouped_means.T\n",
    "\n",
    "plt.figure(figsize=(14, 8))\n",
    "grouped_means_T.plot(kind='bar', figsize=(14, 8), colormap='viridis')\n",
    "\n",
    "plt.title('Mean Feature Values by Wine Quality')\n",
    "plt.ylabel('Mean Value')\n",
    "plt.xlabel('Features')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend(title='Quality', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7705c113",
   "metadata": {},
   "source": [
    "# Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f849965f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tigran Fahradyan\n",
    "data = wine_data.to_numpy()\n",
    "\n",
    "CV = 5\n",
    "\n",
    "def split_data(data, seed=42):\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(len(data))\n",
    "    \n",
    "    train_end = int(0.9 * len(data))\n",
    "\n",
    "    train = data[indices[:train_end]]\n",
    "    test = data[indices[train_end:]]\n",
    "\n",
    "    return train, test\n",
    "\n",
    "def replace_nans(train, test):\n",
    "    train_mean = np.nanmean(train[:, :-1], axis=0)\n",
    "    for dataset in [train, test]:\n",
    "        for i in range(dataset.shape[1] - 1):\n",
    "            nan_mask = np.isnan(dataset[:, i])\n",
    "            dataset[nan_mask, i] = train_mean[i]\n",
    "    return train, test\n",
    "\n",
    "train, test = split_data(data, seed=42)\n",
    "train, test = replace_nans(train, test)\n",
    "\n",
    "X_train, y_train = train[:, :-1], train[:, -1].astype(int)\n",
    "X_test, y_test = test[:, :-1], test[:, -1].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe12c8f",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67897185",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayes:\n",
    "    def __init__(self, n_bins=10):\n",
    "        self.n_bins = n_bins\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.n_features = X.shape[1]\n",
    "        self.classes = np.unique(y)\n",
    "        self.K = len(self.classes)\n",
    "        self.N = len(y)\n",
    "\n",
    "        self.class_counts = {c: np.sum(y == c) for c in self.classes}\n",
    "        self.priors = {\n",
    "            c: (self.class_counts[c] + 1) / (self.N + self.K)\n",
    "            for c in self.classes\n",
    "        }\n",
    "\n",
    "        self.bins = []\n",
    "        self.X_binned = np.zeros_like(X, dtype=int)\n",
    "        for i in range(self.n_features):\n",
    "            col, edges = pd.cut(X[:, i], bins=self.n_bins, retbins=True, labels=False, duplicates='drop')\n",
    "            self.X_binned[:, i] = col\n",
    "            self.bins.append(edges)\n",
    "\n",
    "        self.feature_counts = {\n",
    "            c: np.zeros((self.n_features, self.n_bins), dtype=int)\n",
    "            for c in self.classes\n",
    "        }\n",
    "\n",
    "        for x, label in zip(self.X_binned, y):\n",
    "            for i, bin_idx in enumerate(x):\n",
    "                self.feature_counts[label][i][bin_idx] += 1\n",
    "\n",
    "    def _predict_sample(self, x):\n",
    "        x_binned = []\n",
    "        for i, val in enumerate(x):\n",
    "            bin_idx = np.digitize(val, self.bins[i]) - 1\n",
    "            bin_idx = min(max(bin_idx, 0), self.n_bins - 1)\n",
    "            x_binned.append(bin_idx)\n",
    "\n",
    "        best_class = None\n",
    "        max_log_prob = -np.inf\n",
    "\n",
    "        for c in self.classes:\n",
    "            log_prob = np.log(self.priors[c])\n",
    "\n",
    "            for i, bin_idx in enumerate(x_binned):\n",
    "                count = self.feature_counts[c][i][bin_idx]\n",
    "                total = self.class_counts[c]\n",
    "                prob = (count + 1) / (total + self.K)\n",
    "                log_prob += np.log(prob)\n",
    "\n",
    "            if log_prob > max_log_prob:\n",
    "                max_log_prob = log_prob\n",
    "                best_class = c\n",
    "\n",
    "        return best_class\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_sample(x) for x in X])\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)\n",
    "\n",
    "nb = NaiveBayes(n_bins=10)\n",
    "nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe22b628",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "gnb = GaussianNB(var_smoothing=1e-9)\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "gnb_val_preds = gnb.predict(X_val)\n",
    "gnb_test_preds = gnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd20abe8-9c9d-44b0-b8aa-034edd447025",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa66bf-2a45-44a1-92b0-3bbbbd09c3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "hparams = {\n",
    "    \"criterion\": [\"gini\", \"entropy\"],\n",
    "    \"splitter\": [\"best\", \"random\"],\n",
    "}\n",
    "\n",
    "decision_tree = DecisionTreeClassifier(random_state=42)\n",
    "grid_search_decision_tree = GridSearchCV(\n",
    "    decision_tree,\n",
    "    param_grid=hparams,\n",
    "    scoring=\"accuracy\",\n",
    "    cv=CV\n",
    ")\n",
    "grid_search_decision_tree.fit(X_train, y_train);\n",
    "\n",
    "dt = grid_search_decision_tree.best_estimator_\n",
    "\n",
    "print(f\"The best hparam configuration for decision tree is {grid_search_decision_tree.best_params_} with score {grid_search_decision_tree.best_score_:.4f}\")\n",
    "\n",
    "decision_tree_test_preds = grid_search_decision_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69821172",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=None,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=42,\n",
    "    n_jobs=-1\n",
    ")\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf_test_preds = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e144dbff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(solver='svd')\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "lda_test_preds = lda.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d214c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# kNN - Suren Hakobyan\n",
    "\n",
    "# Gaussian Naive Bayes - Satine Aghababyan\n",
    "# Logistic Regression - Suren Hakobyan\n",
    "# Decision Tree - Tigran Fahradyan\n",
    "# Random Forest - Satine Aghababyan\n",
    "# SVM - Suren Hakobyan\n",
    "# Neural Networks - Tigran Fahradyan\n",
    "# LDA - Satine Aghababyan\n",
    "# QDA - Suren Hakobyan\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ee7229",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5314d410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# հետո կերևա\n",
    "\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def evaluate_model(name, model, X_test, y_test, is_custom=False):\n",
    "    print(f\"\\n{name}\")\n",
    "    if is_custom:\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print(f\"Accuracy: {acc:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, zero_division=0))\n",
    "\n",
    "\n",
    "    all_classes = list(range(0, 11))\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=all_classes)\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "    plt.title(f\"{name} - Confusion Matrix\")\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"Actual\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "evaluate_model(\"Naive Bayes\", nb, X_test, y_test, is_custom=True)\n",
    "\n",
    "evaluate_model(\"Gaussian Naive Bayes\", gnb, X_test, y_test)\n",
    "\n",
    "evaluate_model(\"Random Forest\", rf, X_test, y_test)\n",
    "\n",
    "evaluate_model(\"Linear Discriminant Analysis\", lda, X_test, y_test)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

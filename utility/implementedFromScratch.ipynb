{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d3cbd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNaiveBayes:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        self.parameters = {}\n",
    "        for cls in self.classes:\n",
    "            X_c = X[y == cls]\n",
    "            mean = X_c.mean(axis=0)\n",
    "            var = X_c.var(axis=0) + 1e-9\n",
    "            prior = X_c.shape[0] / X.shape[0]\n",
    "            self.parameters[cls] = (mean, var, prior)\n",
    "\n",
    "    def _predict_row(self, x):\n",
    "        posteriors = []\n",
    "        for cls in self.classes:\n",
    "            mean, var, prior = self.parameters[cls]\n",
    "            log_likelihood = -0.5 * np.sum(np.log(2 * math.pi * var))\n",
    "            log_likelihood -= 0.5 * np.sum(((x - mean) ** 2) / var)\n",
    "            posterior = log_likelihood + np.log(prior)\n",
    "            posteriors.append(posterior)\n",
    "        return self.classes[np.argmax(posteriors)]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self._predict_row(x) for x in X])\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)\n",
    "\n",
    "gnb = GaussianNaiveBayes()\n",
    "gnb.fit(X_train, y_train)\n",
    "\n",
    "print(\"Gausian Naive Bayes - Validation Accuracy: \", gnb.score(X_val, y_val))\n",
    "print(\"Gausian Naive Bayes - Test Accuracy: \", gnb.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47df377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def gini(groups, classes):\n",
    "    n_instances = float(sum(len(group) for group in groups))\n",
    "    gini_score = 0.0\n",
    "    for group in groups:\n",
    "        size = len(group)\n",
    "        if size == 0: continue\n",
    "        score = sum((list(group[:, -1]).count(cls) / size) ** 2 for cls in classes)\n",
    "        gini_score += (1 - score) * (size / n_instances)\n",
    "    return gini_score\n",
    "\n",
    "def test_split(index, value, dataset):\n",
    "    left = dataset[dataset[:, index] < value]\n",
    "    right = dataset[dataset[:, index] >= value]\n",
    "    return left, right\n",
    "\n",
    "def get_split(dataset, n_features):\n",
    "    class_values = list(set(dataset[:, -1]))\n",
    "    features = random.sample(range(dataset.shape[1] - 1), n_features)\n",
    "    best_index, best_value, best_score, best_groups = 999, 999, 999, None\n",
    "    for index in features:\n",
    "        for row in dataset:\n",
    "            groups = test_split(index, row[index], dataset)\n",
    "            score = gini(groups, class_values)\n",
    "            if score < best_score:\n",
    "                best_index, best_value, best_score, best_groups = index, row[index], score, groups\n",
    "    return {'index': best_index, 'value': best_value, 'groups': best_groups}\n",
    "\n",
    "def to_terminal(group):\n",
    "    outcomes = [row[-1] for row in group]\n",
    "    return Counter(outcomes).most_common(1)[0][0]\n",
    "\n",
    "def split(node, max_depth, min_size, n_features, depth):\n",
    "    left, right = node['groups']\n",
    "    del node['groups']\n",
    "\n",
    "    if left.shape[0] == 0 or right.shape[0] == 0:\n",
    "        node['left'] = node['right'] = to_terminal(np.vstack((left, right)))\n",
    "        return\n",
    "\n",
    "    if depth >= max_depth:\n",
    "        node['left'], node['right'] = to_terminal(left), to_terminal(right)\n",
    "        return\n",
    "\n",
    "    if len(left) <= min_size:\n",
    "        node['left'] = to_terminal(left)\n",
    "    else:\n",
    "        node['left'] = get_split(left, n_features)\n",
    "        split(node['left'], max_depth, min_size, n_features, depth + 1)\n",
    "\n",
    "    if len(right) <= min_size:\n",
    "        node['right'] = to_terminal(right)\n",
    "    else:\n",
    "        node['right'] = get_split(right, n_features)\n",
    "        split(node['right'], max_depth, min_size, n_features, depth + 1)\n",
    "\n",
    "def build_tree(train, max_depth, min_size, n_features):\n",
    "    root = get_split(train, n_features)\n",
    "    split(root, max_depth, min_size, n_features, 1)\n",
    "    return root\n",
    "\n",
    "def predict_tree(node, row):\n",
    "    if row[node['index']] < node['value']:\n",
    "        if isinstance(node['left'], dict):\n",
    "            return predict_tree(node['left'], row)\n",
    "        else:\n",
    "            return node['left']\n",
    "    else:\n",
    "        if isinstance(node['right'], dict):\n",
    "            return predict_tree(node['right'], row)\n",
    "        else:\n",
    "            return node['right']\n",
    "\n",
    "class RandomForest:\n",
    "    def __init__(self, n_trees=10, max_depth=10, min_size=1, sample_size=1.0, n_features=None):\n",
    "        self.n_trees = n_trees\n",
    "        self.max_depth = max_depth\n",
    "        self.min_size = min_size\n",
    "        self.sample_size = sample_size\n",
    "        self.n_features = n_features\n",
    "        self.trees = []\n",
    "\n",
    "    def subsample(self, dataset):\n",
    "        n_sample = round(len(dataset) * self.sample_size)\n",
    "        return dataset[np.random.choice(len(dataset), n_sample, replace=True)]\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        data = np.hstack((X, y.reshape(-1, 1)))\n",
    "        self.trees = []\n",
    "        for _ in range(self.n_trees):\n",
    "            sample = self.subsample(data)\n",
    "            tree = build_tree(sample, self.max_depth, self.min_size, self.n_features or int(np.sqrt(X.shape[1])))\n",
    "            self.trees.append(tree)\n",
    "\n",
    "    def predict_row(self, row):\n",
    "        predictions = [predict_tree(tree, row) for tree in self.trees]\n",
    "        return Counter(predictions).most_common(1)[0][0]\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([self.predict_row(row) for row in X])\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        return np.mean(predictions == y)\n",
    "\n",
    "rf = RandomForest(n_trees=10, max_depth=10, min_size=2, sample_size=0.9)\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nRandom Forest - Validation Accuracy: \", rf.score(X_val, y_val))\n",
    "print(\"Random Forest - Test Accuracy: \", rf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ea1497",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LDA:\n",
    "    def fit(self, X, y):\n",
    "        self.classes = np.unique(y)\n",
    "        n_features = X.shape[1]\n",
    "        self.means = {}\n",
    "        self.priors = {}\n",
    "        self.Sw = np.zeros((n_features, n_features))\n",
    "\n",
    "        for cls in self.classes:\n",
    "            X_c = X[y == cls]\n",
    "            self.means[cls] = np.mean(X_c, axis=0)\n",
    "            self.priors[cls] = X_c.shape[0] / X.shape[0]\n",
    "            self.Sw += np.cov(X_c, rowvar=False) * (X_c.shape[0] - 1)\n",
    "\n",
    "        self.Sw /= (X.shape[0] - len(self.classes))  # Pooled covariance matrix\n",
    "        self.Sw_inv = np.linalg.inv(self.Sw)\n",
    "\n",
    "    def _discriminant(self, x, cls):\n",
    "        mu_k = self.means[cls]\n",
    "        prior = self.priors[cls]\n",
    "        return (x @ self.Sw_inv @ mu_k) - 0.5 * (mu_k @ self.Sw_inv @ mu_k) + np.log(prior)\n",
    "\n",
    "    def predict(self, X):\n",
    "        return np.array([\n",
    "            max(self.classes, key=lambda cls: self._discriminant(x, cls)) for x in X\n",
    "        ])\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return np.mean(self.predict(X) == y)\n",
    "\n",
    "lda = LDA()\n",
    "lda.fit(X_train, y_train)\n",
    "\n",
    "print(\"\\nLDA - Validation Accuracy: \", lda.score(X_val, y_val))\n",
    "print(\"LDA - Test Accuracy: \", lda.score(X_test, y_test))"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
